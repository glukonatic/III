{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13Pro",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glukonatic/III/blob/master/13Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s",
        "cellView": "form"
      },
      "source": [
        "#@title Импорт библиотек\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import re \n",
        "\n",
        "from tensorflow.keras.models import Model, load_model \n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input \n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras import utils \n",
        "from tensorflow.keras.utils import plot_model \n",
        "\n",
        "import yaml "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "cellView": "form",
        "outputId": "f681451c-08c9-404f-893a-d1d9539f4fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Подключаем гуглдрайв\n",
        "\n",
        "from google.colab import files \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBazpYMcvOsr",
        "cellView": "form"
      },
      "source": [
        "#@title Класс для ДЗ\n",
        "\n",
        "class HW13():\n",
        "\n",
        "  def __init__(self):\n",
        "    corpuspath = '/content/drive/My Drive/III/13/Диалоги(рассказы).yml'\n",
        "    corpus = open(corpuspath, 'r') \n",
        "    document = yaml.safe_load(corpus) \n",
        "    self.conversations = document['разговоры']\n",
        "    self.questions = list()\n",
        "    self.answers = list() \n",
        "    self.results = list()\n",
        "    print('Класс инициализирован.')\n",
        "\n",
        "  def prepare(self, tknzr_type = 'simple'):\n",
        "\n",
        "    self.tokenizer = Tokenizer()\n",
        "\n",
        "    for con in self.conversations: \n",
        "      if type(con[1]) == str:\n",
        "        self.questions.append(con[0]) \n",
        "        self.answers.append('<START> ' + (' ').join(con[1:]) + ' <END>') \n",
        "\n",
        "    if tknzr_type == 'with_punctuation':\n",
        "      to_tokenize = '.,!?'\n",
        "      self.questions = list(map(lambda l: re.sub(r'(['+to_tokenize+'])', r' \\1 ', str(l)), self.questions))\n",
        "      self.answers = list(map(lambda l: re.sub(r'(['+to_tokenize+'])', r' \\1 ', str(l)), self.answers))\n",
        "\n",
        "    self.tokenizer.fit_on_texts(self.questions + self.answers) \n",
        "    vocabularyItems = list(self.tokenizer.word_index.items()) \n",
        "    self.vocabularySize = len(vocabularyItems)+1 \n",
        "\n",
        "    tokenizedQuestions = self.tokenizer.texts_to_sequences(self.questions) \n",
        "    self.maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) \n",
        "    paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=self.maxLenQuestions, padding='post')\n",
        "    self.encoderForInput = np.array(paddedQuestions) \n",
        "\n",
        "    tokenizedAnswers = self.tokenizer.texts_to_sequences(self.answers) \n",
        "    self.maxLenAnswers = max([len(x) for x in tokenizedAnswers]) \n",
        "    paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=self.maxLenAnswers, padding='post')\n",
        "    self.decoderForInput = np.array(paddedAnswers) \n",
        "\n",
        "    for i in range(len(tokenizedAnswers)) : \n",
        "      tokenizedAnswers[i] = tokenizedAnswers[i][1:] \n",
        "    paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=self.maxLenAnswers , padding='post')\n",
        "    self.oneHotAnswers = utils.to_categorical(paddedAnswers, self.vocabularySize) \n",
        "    self.decoderForOutput = np.array(self.oneHotAnswers) \n",
        "    print('Данные подготовлены.')\n",
        "  \n",
        "  def create_nn(self):\n",
        "\n",
        "    self.encoderInputs = Input(shape=(11, )) \n",
        "    encoderEmbedding = Embedding(self.vocabularySize, 200,  mask_zero=True) (self.encoderInputs)\n",
        "    encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "    self.encoderStates = [state_h, state_c]\n",
        "\n",
        "    self.decoderInputs = Input(shape=(13, )) \n",
        "    self.decoderEmbedding = Embedding(self.vocabularySize, 200, mask_zero=True) (self.decoderInputs) \n",
        "    self.decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "    decoderOutputs , _ , _ = self.decoderLSTM (self.decoderEmbedding, initial_state=self.encoderStates)\n",
        "    self.decoderDense = Dense(self.vocabularySize, activation='softmax') \n",
        "    output = self.decoderDense (decoderOutputs)\n",
        "\n",
        "    self.model = Model([self.encoderInputs, self.decoderInputs], output)\n",
        "    self.model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "    print('Модель скомпилирована.')\n",
        "    \n",
        "  def fit(self, bs=50, ep=10):\n",
        "\n",
        "    print('Запуск обучения...') \n",
        "    self.model.fit([self.encoderForInput , self.decoderForInput], \n",
        "                   self.decoderForOutput, \n",
        "                   batch_size=bs, epochs=ep, verbose = 0) \n",
        "    print('Цикл обучения завершен')\n",
        "\n",
        "  def makeInferenceModels(self):\n",
        "  \n",
        "    encoderModel = Model(self.encoderInputs, self.encoderStates) \n",
        "\n",
        "    decoderStateInput_h = Input(shape=(200 ,)) \n",
        "    decoderStateInput_c = Input(shape=(200 ,))\n",
        "\n",
        "    decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] \n",
        "\n",
        "    decoderOutputs, state_h, state_c = self.decoderLSTM(self.decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "\n",
        "    decoderStates = [state_h, state_c] \n",
        "    decoderOutputs = self.decoderDense(decoderOutputs) \n",
        "\n",
        "    decoderModel = Model([self.decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "    return encoderModel , decoderModel\n",
        "\n",
        "\n",
        "  def strToTokens(self, sentence: str): \n",
        "\n",
        "    words = sentence.lower().split() \n",
        "    tokensList = list() \n",
        "\n",
        "    for word in words: \n",
        "      tokensList.append(self.tokenizer.word_index[word]) if word in self.tokenizer.word_docs.keys() else tokensList.append(1) \n",
        "\n",
        "    return pad_sequences([tokensList], maxlen=self.maxLenQuestions , padding='post')\n",
        "\n",
        "\n",
        "  def main(self, dialog_type = 'manual'):\n",
        "    \n",
        "    encModel, decModel = self.makeInferenceModels() \n",
        "\n",
        "    self.auto_phrases = ['Привет','Как дела','Почему так','Ты вообще кто','А если найду','Ужас какой']\n",
        "\n",
        "    for i in range(6): \n",
        "\n",
        "      if dialog_type == 'auto':\n",
        "        statesValues = encModel.predict(self.strToTokens(self.auto_phrases[i]))\n",
        "      else:\n",
        "        statesValues = encModel.predict(self.strToTokens(input( 'Задайте вопрос : ' )))\n",
        "\n",
        "\n",
        "      emptyTargetSeq = np.zeros((1, 1))    \n",
        "      emptyTargetSeq[0, 0] = self.tokenizer.word_index['start'] \n",
        "\n",
        "      stopCondition = False \n",
        "      decodedTranslation = '' \n",
        "\n",
        "      while not stopCondition : \n",
        "\n",
        "        decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "      \n",
        "        sampledWordIndex = np.argmax(decOutputs, axis=-1) \n",
        "        sampledWord = None \n",
        "        for word , index in self.tokenizer.word_index.items():\n",
        "          if sampledWordIndex == index: \n",
        "            decodedTranslation += ' {}'.format(word) \n",
        "            sampledWord = word \n",
        "      \n",
        "        if sampledWord == 'end' or len(decodedTranslation.split()) > self.maxLenAnswers:\n",
        "          stopCondition = True \n",
        "\n",
        "        emptyTargetSeq = np.zeros((1, 1)) \n",
        "        emptyTargetSeq[0, 0] = sampledWordIndex \n",
        "        statesValues = [h, c] \n",
        "\n",
        "      if dialog_type == 'auto':\n",
        "        self.results.append(decodedTranslation[:-3]) \n",
        "      else:\n",
        "        print(decodedTranslation[:-3]) \n",
        "\n",
        "  def clear_vars(self):\n",
        "    \n",
        "    self.questions.clear()\n",
        "    self.answers.clear()\n",
        "    del self.tokenizer\n",
        "    del self.vocabularySize\n",
        "    del self.maxLenQuestions\n",
        "    del self.encoderForInput\n",
        "    del self.maxLenAnswers\n",
        "    del self.decoderForInput\n",
        "    del self.oneHotAnswers\n",
        "    del self.decoderForOutput\n",
        "\n",
        "    print('Переменные удалены и очищены')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMavUuzC7IlQ",
        "cellView": "form",
        "outputId": "422e42a3-1519-41ee-d1d8-b1d1c107bc03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Главный блок\n",
        "\n",
        "#@markdown Количество циклов обучения по 10 эпох:\n",
        "cycles =  10#@param {type: \"number\"}\n",
        "\n",
        "first = HW13()\n",
        "\n",
        "first.prepare()\n",
        "first.create_nn()\n",
        "\n",
        "for i in range(cycles):\n",
        "  first.fit()\n",
        "  first.main('auto')\n",
        "\n",
        "first.clear_vars()\n",
        "\n",
        "second = HW13()\n",
        "\n",
        "second.prepare('with_punctuation')\n",
        "second.create_nn()\n",
        "\n",
        "for i in range(cycles):\n",
        "  second.fit()\n",
        "  second.main('auto')\n",
        "\n",
        "second.clear_vars()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Класс инициализирован.\n",
            "Данные подготовлены.\n",
            "Модель скомпилирована.\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_2:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Переменные удалены и очищены\n",
            "Класс инициализирован.\n",
            "Данные подготовлены.\n",
            "Модель скомпилирована.\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Запуск обучения...\n",
            "Цикл обучения завершен\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input Tensor(\"input_24:0\", shape=(None, 13), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n",
            "Переменные удалены и очищены\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLB4gPZO7XP3",
        "outputId": "ed5d3bb1-1862-44fe-cf19-84ab4de4d947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(first.results)\n",
        "print(second.results)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' да ', ' да ', ' не знаю ', ' нет нет ', ' да ', ' да ', ' что случилось ', ' да товарищ командир ', ' не знаю ', ' нет я не знаю а что ', ' как же вы знаете ', ' а где ', ' ну как что вы с вами делать ', ' а почему бы и нет ', ' потому что у меня есть есть ', ' я не знаю я а ты мне не об этом этом ', ' как мы сами и с тобой и я ', ' а где ', ' что ты здесь делаешь ', ' все в порядке ', ' потому что у вас там нет ', ' меня я должен знать сейчас пойду ты ', ' как мы с вами все и в порядке ', ' ну на что нибудь ', ' что ты здесь делаешь ', ' вот так ', ' ты так просто ', ' меня я пойду один сейчас ты меня не умею меня ', ' ну и сказала все и его к нет ', ' на кто нибудь из чего ', ' что ты здесь делаешь ', ' за вами генерал ', ' потому что у вас есть они ', ' а я конечно не сколько ', ' ну и сказала я тоже не знаю ', ' ну на что нибудь ', ' что тебе надо человек ', ' за вами ну вот так ', ' потому что у вас есть ', ' а я конечно не сказала что ли кто не его в дело ', ' мы будем из тебя ', ' на я тебя могу ему еще спасибо будем ', ' что ты здесь делаешь ', ' за все теперь ты о том у меня зовут ', ' потому что у вас все вот так знаешь ', ' а я хочу что это сделал ', ' мы будем об этом ', ' ну такой ', ' что ты здесь делаешь ', ' за все теперь о ', ' потому что у вас там ничего нет ', ' я не а мне не нравится ', ' мы будем об этом ', ' ну такой ', ' что ты здесь делаешь ', ' за ночь сделали пятнадцать у тебя ', ' потому что у меня там ничего нет ', ' а я почему не знаю ', ' мы будем да по об этом ', ' ну такой ']\n",
            "[' да ', ' да ', ' ничего ', ' нет нет ', ' да ', ' ну да ', ' что вы знаете ', ' да вот ', ' ничего ', ' я я знаю я тебя не знаю ', ' как именно ', ' а вот кто ', ' что вы знаете ', ' да все в порядке ', ' мне так ', ' я я не знаю ну ка мне ', ' как же вы кто их ', ' на каком смысле ', ' что тебе надо человек ', ' да вот так уж не сейчас ', ' не хочу ', ' я я не могу я ничего с тобой ', ' как же вы если если в быть я ', ' ну вот так ', ' что ты здесь делаешь ', ' вот вам о чем только было от меня ', ' не хочу ', ' я я в ну ж ж ничего ж ', ' как хочешь ', ' ну да ', ' что ты здесь делаешь ', ' за тобой все в порядке ', ' ну ', ' я я не могу в на ну ', ' как тогда я ', ' с вами хочет чтобы тоже ', ' что ты здесь делаешь ', ' за тобой все ', ' ну ', ' я я в ну что ж и ничего а ', ' а вы кто же теперь ', ' с вами хочет чтобы тоже ', ' что тебе надо человек ', ' за вообще тоже кое что надо надо там ', ' ну ', ' я я в ну чтобы все ему ну ', ' а как ', ' с вами ', ' что тебе надо человек ', ' за десять минут вот ', ' да так ', ' я я в ну что ж нет то что ', ' а я все это ', ' с а что здесь ничего ', ' что ты здесь делаешь ', ' за десять минут пятнадцать ', ' да так я все мы с порядке ', ' я я в ну что то ж хотел ', ' а я как его не это теперь ', ' с это да ']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}